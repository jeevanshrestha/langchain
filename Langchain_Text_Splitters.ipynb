{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gVgqck7zeNcr",
        "qD0chRF8iZFO"
      ],
      "authorship_tag": "ABX9TyPGYJZoXtGeqvNvPa8jmo0j",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeevanshrestha/langchain/blob/main/Langchain_Text_Splitters.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Langchain Text Splitters"
      ],
      "metadata": {
        "id": "3sNFpkxjO8Jx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initial Setup"
      ],
      "metadata": {
        "id": "_dc1LWznPydS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Install Required Libraries\n"
      ],
      "metadata": {
        "id": "JtMcZrah3tho"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "81A3knUidnaM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8ef6272-0d43-4f85-85c6-64323c6d35d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m727.0/981.5 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m972.8/981.5 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /simple/rapidfuzz/\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m195.8/195.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m304.2/304.2 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install openai langchain langchain-community langchain_huggingface langchain-openai unstructured faiss-cpu grandalf  -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mount Google Drive"
      ],
      "metadata": {
        "id": "gVgqck7zeNcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive to access files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdPti1sleYn-",
        "outputId": "fe6fec93-f047-4332-8997-46d3496e2fad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "neyTrjSJ3IpB"
      },
      "outputs": [],
      "source": [
        "#set working directory\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/GenAI/RAG/')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### OpenAI Key Setup"
      ],
      "metadata": {
        "id": "ErfzayOVogkP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get('genai_course')"
      ],
      "metadata": {
        "id": "kgYZyIN6eQ4-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import Libraries\n"
      ],
      "metadata": {
        "id": "F5XBRsoQ34NR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "m4IOOMEhF2GK"
      },
      "outputs": [],
      "source": [
        "#Import the libraries\n",
        "from langchain_openai import ChatOpenAI\n",
        "from IPython.display import display, Markdown\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cYoBiSuwGanC",
        "outputId": "06726d48-103f-45a6-eef5-f2ab1a5a3154"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/GenAI/RAG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directory = os.path.join(os.getcwd(), 'Unstructured Data')"
      ],
      "metadata": {
        "id": "qUQJnOS-i9Z0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Character Length Based"
      ],
      "metadata": {
        "id": "WpdloLVai4Av"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(f'{directory}/dl-curriculum.pdf')\n",
        "\n",
        "docs = loader.load()\n",
        "\n",
        "splitter = CharacterTextSplitter(\n",
        "    chunk_size=200,\n",
        "    chunk_overlap=0,\n",
        "    separator=''\n",
        ")\n",
        "\n",
        "result = splitter.split_documents(docs)\n",
        "\n",
        "print(result[1].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbrVNkzTi6c3",
        "outputId": "4dd8e8fe-0a46-4ae4-aba6-ddfad7c6149e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ificialneurons\n",
            "2.HistoryofNeuralNetworks\n",
            "â— Earlymodels(Perceptron)â— BackpropagationandMLPsâ— The\"AIWinter\"andresurgenceofneuralnetworksâ— Emergenceofdeeplearning\n",
            "3.PerceptronandMultilayerPerceptrons(MLP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Text Structure Based Splitter"
      ],
      "metadata": {
        "id": "qD0chRF8iZFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text = \"\"\"\n",
        "Space exploration has led to incredible scientific discoveries. From landing on the Moon to exploring Mars, humanity continues to push the boundaries of whatâ€™s possible beyond our planet.\n",
        "\n",
        "These missions have not only expanded our knowledge of the universe but have also contributed to advancements in technology here on Earth. Satellite communications, GPS, and even certain medical imaging techniques trace their roots back to innovations driven by space programs.\n",
        "\"\"\"\n",
        "\n",
        "# Initialize the splitter\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=100,\n",
        "    chunk_overlap=10,\n",
        ")\n",
        "\n",
        "# Perform the split\n",
        "chunks = splitter.split_text(text)\n",
        "\n",
        "print(len(chunks))\n",
        "print(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_A0_xIMicXE",
        "outputId": "aeb48d05-2d1b-45d5-ba63-1d2b9ec36db6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n",
            "['Space exploration has led to incredible scientific discoveries. From landing on the Moon to', 'Moon to exploring Mars, humanity continues to push the boundaries of whatâ€™s possible beyond our', 'our planet.', 'These missions have not only expanded our knowledge of the universe but have also contributed to', 'to advancements in technology here on Earth. Satellite communications, GPS, and even certain', 'certain medical imaging techniques trace their roots back to innovations driven by space programs.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b9iRRDUniiuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "B87QlbQbik3P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Semantic Meaning Based"
      ],
      "metadata": {
        "id": "LMU4VqkNjGd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_experimental -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEJc69HWjRqN",
        "outputId": "b103a5e9-ee33-4334-b13e-9272a1ddd09b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/209.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m81.9/209.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "text_splitter = SemanticChunker(\n",
        "    OpenAIEmbeddings(api_key=api_key), breakpoint_threshold_type=\"standard_deviation\",\n",
        "    breakpoint_threshold_amount=3\n",
        ")\n",
        "\n",
        "sample = \"\"\"\n",
        "Farmers were working hard in the fields, preparing the soil and planting seeds for the next season. The sun was bright, and the air smelled of earth and fresh grass. The Indian Premier League (IPL) is the biggest cricket league in the world. People all over the world watch the matches and cheer for their favourite teams.\n",
        "\n",
        "\n",
        "Terrorism is a big danger to peace and safety. It causes harm to people and creates fear in cities and villages. When such attacks happen, they leave behind pain and sadness. To fight terrorism, we need strong laws, alert security forces, and support from people who care about peace and safety.\n",
        "\"\"\"\n",
        "\n",
        "docs = text_splitter.create_documents([sample])\n",
        "print(len(docs))\n",
        "print(docs)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChybuMDvjLSU",
        "outputId": "1270fe8c-77c8-4202-a536-832730561a9d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "[Document(metadata={}, page_content='\\nFarmers were working hard in the fields, preparing the soil and planting seeds for the next season. The sun was bright, and the air smelled of earth and fresh grass. The Indian Premier League (IPL) is the biggest cricket league in the world. People all over the world watch the matches and cheer for their favourite teams. Terrorism is a big danger to peace and safety. It causes harm to people and creates fear in cities and villages. When such attacks happen, they leave behind pain and sadness. To fight terrorism, we need strong laws, alert security forces, and support from people who care about peace and safety. ')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XlvaQe26jXkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Markdown Splitting"
      ],
      "metadata": {
        "id": "0pVZkLOvjg9a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter,Language\n",
        "\n",
        "text = \"\"\"\n",
        "# Project Name: Smart Student Tracker\n",
        "\n",
        "A simple Python-based project to manage and track student data, including their grades, age, and academic status.\n",
        "\n",
        "\n",
        "## Features\n",
        "\n",
        "- Add new students with relevant info\n",
        "- View student details\n",
        "- Check if a student is passing\n",
        "- Easily extendable class-based design\n",
        "\n",
        "\n",
        "## ðŸ›  Tech Stack\n",
        "\n",
        "- Python 3.10+\n",
        "- No external dependencies\n",
        "\n",
        "\n",
        "## Getting Started\n",
        "\n",
        "1. Clone the repo\n",
        "   ```bash\n",
        "   git clone https://github.com/your-username/student-tracker.git\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Initialize the splitter\n",
        "splitter = RecursiveCharacterTextSplitter.from_language(\n",
        "    language=Language.MARKDOWN,\n",
        "    chunk_size=200,\n",
        "    chunk_overlap=0,\n",
        ")\n",
        "\n",
        "# Perform the split\n",
        "chunks = splitter.split_text(text)\n",
        "\n",
        "print(len(chunks))\n",
        "print(chunks[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtV7NW9KjiQN",
        "outputId": "cd19618c-41df-490c-8788-4b8527cd0433"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "# Project Name: Smart Student Tracker\n",
            "\n",
            "A simple Python-based project to manage and track student data, including their grades, age, and academic status.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XA4LpuhcjkdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Python Code Splitting"
      ],
      "metadata": {
        "id": "Y1rrRV8JjnLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter,Language\n",
        "\n",
        "text = \"\"\"\n",
        "class Student:\n",
        "    def __init__(self, name, age, grade):\n",
        "        self.name = name\n",
        "        self.age = age\n",
        "        self.grade = grade  # Grade is a float (like 8.5 or 9.2)\n",
        "\n",
        "    def get_details(self):\n",
        "        return self.name\"\n",
        "\n",
        "    def is_passing(self):\n",
        "        return self.grade >= 6.0\n",
        "\n",
        "\n",
        "# Example usage\n",
        "student1 = Student(\"Aarav\", 20, 8.2)\n",
        "print(student1.get_details())\n",
        "\n",
        "if student1.is_passing():\n",
        "    print(\"The student is passing.\")\n",
        "else:\n",
        "    print(\"The student is not passing.\")\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Initialize the splitter\n",
        "splitter = RecursiveCharacterTextSplitter.from_language(\n",
        "    language=Language.PYTHON,\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=0,\n",
        ")\n",
        "\n",
        "# Perform the split\n",
        "chunks = splitter.split_text(text)\n",
        "\n",
        "print(len(chunks))\n",
        "print(chunks[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2pYJWcXjo6f",
        "outputId": "ff8e0e02-8190-4913-b888-5208e2eca480"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n",
            "# Example usage\n",
            "student1 = Student(\"Aarav\", 20, 8.2)\n",
            "print(student1.get_details())\n",
            "\n",
            "if student1.is_passing():\n",
            "    print(\"The student is passing.\")\n",
            "else:\n",
            "    print(\"The student is not passing.\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZC-Uhf0djp2y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}